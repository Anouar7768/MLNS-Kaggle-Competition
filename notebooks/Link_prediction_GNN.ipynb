{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b4af0b",
   "metadata": {},
   "source": [
    "# MLNS Kaggle challenge: link prediction using GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d612f",
   "metadata": {},
   "source": [
    "### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f696a05",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d44cf",
   "metadata": {},
   "source": [
    "### Import and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a139619",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df = pd.read_csv(\"node_information.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3bf885",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(node_df.shape)\n",
    "node_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c3c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df = pd.read_csv(\"train.txt\", header=None, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_df_train_padded = copy.deepcopy(node_df)\n",
    "k=0\n",
    "j=0\n",
    "while k<7599:\n",
    "    if node_df[0].iloc[j] != k:\n",
    "        index = k-0.5\n",
    "        temp_list = [k]\n",
    "        temp_list[1:] = [0 for i in range(932)]\n",
    "        node_df_train_padded.loc[index] = temp_list\n",
    "        node_df_train_padded = node_df_train_padded.sort_index().reset_index(drop=True)\n",
    "    else:\n",
    "        j+=1\n",
    "    k+=1\n",
    "\n",
    "node_df_train_padded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = node_df_train_padded.iloc[:, 1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2332af",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_edges = graph_df[graph_df[2] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8a2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([list(positive_edges[0]),\n",
    "                           list(positive_edges[1])], dtype=torch.long)\n",
    "x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325592bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = T.RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.0,\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=False,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")\n",
    "train_data, val_data, test_data = split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b98cef",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(\n",
    "            dim=-1\n",
    "        )  # product of a pair of nodes on each edge\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "    \n",
    "\n",
    "def train_link_predictor(\n",
    "    model, train_data, val_data, optimizer, criterion, n_epochs=100\n",
    "):\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "        # sampling training negatives for every training epoch\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "            num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "        edge_label_index = torch.cat(\n",
    "            [train_data.edge_label_index, neg_edge_index],\n",
    "            dim=-1,\n",
    "        )\n",
    "        edge_label = torch.cat([\n",
    "            train_data.edge_label,\n",
    "            train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "        ], dim=0)\n",
    "\n",
    "        out = model.decode(z, edge_label_index).view(-1)\n",
    "        loss = criterion(out, edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_auc = eval_link_predictor(model, val_data)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_link_predictor(model, data):\n",
    "\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "def test_link_predictor(model, data):\n",
    "    \n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    output = [0 for i in range(len(out))]\n",
    "    for k in range(len(out)):\n",
    "        if out[k]>=0.5:\n",
    "            output[k] = 1\n",
    "        else:\n",
    "            pass\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a96ba",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98525c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(932, 128, 64)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "model = train_link_predictor(model, train_data, val_data, optimizer, criterion, n_epochs = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c1091",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af90127",
   "metadata": {},
   "source": [
    "### Import and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e653a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.txt\", header=None, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07550446",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_test = torch.tensor([list(test_df[0]),\n",
    "                           list(test_df[1])], dtype=torch.long)\n",
    "x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "data_test = Data(x=x, edge_index=edge_index_test, edge_label_index = edge_index_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f92eca",
   "metadata": {},
   "source": [
    "### Prediction generation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = test_link_predictor(model, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c632d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test samples \n",
    "\n",
    "nb_submission = 18\n",
    "with open(\"test.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    test_set = list(reader)\n",
    "test_set = [element[0].split(\" \") for element in test_set]\n",
    "\n",
    "# Make random predictions\n",
    "\n",
    "predictions = zip(np.array(range(len(test_set))), y_pred)\n",
    "\n",
    "# note: Kaggle requires that you add \"ID\" and \"category\" column headers\n",
    "\n",
    "with open(f\"data/submission_{nb_submission}.csv\",\"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(i for i in [\"ID\", \"Predicted\"])\n",
    "    for row in predictions:\n",
    "         csv_out.writerow(row)\n",
    "    pred.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30359721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
